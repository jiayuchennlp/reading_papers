# A Survey of Large Language Models
## Abstract
-  **four major aspects of LLMs**
    - **pre-trainingg** (how to pre-train a capable LLM)
    - **adaptation tuning**(how to effectively adapt pre-trained LLMs for better use)
    - **utilization**(how to use LLMs for solving various downstream tasks)
    - **capacity evaluation** (how to evaluate the abilities of LLMs and existing empirical findings).
 -  summarize the available resources for developing LLMs
 -  discuss the remaining issues for future directions

## Introdution
从技术上来说，语言模型（LM）是一种能推动机器智能的手段。语言模型旨在对单词序列生成的可能性进行建模，从而预测未来的词汇。语言模型的发展经历了以下**四个阶段**：
1. **Statistical language models (SLM).**： 基于统计学习的方法，例如基于Markov假设推测下一个词。利用固定窗口n作为上下文窗口的语言模型称为*n-gram LM*。 这些方法的缺点是数据稀疏及维数灾难。
2. **Neural language models (NLM)**： 利用神经网络（如RNN）来建模单词序列的概率，利用*distributed representation*来表示词，可以利用到更长的上下文信息。其中涌现的重要思想是，采用语言模型来学习更好的表征向量，代表工作如*word2vec*。
3. **Pre-trained language models (PLM)**： 早期，*ELMo*提出了基于双向循环神经网络（*biLSTM*）的模型结构。随着*Transformer*结构的出现，*Bert*在基于双向*Transformer*结构，结合多种预训练任务（*Mask and predict& next word prediction*）,在各项任务上都取得了很大进展。*pre-training and fine-tuning* 的框架成为该时期的主流范式。同时也涌现了许多其他的模型结构（如*GPT*，*T5*）。
4. **Large language models (LLM).**：研究发现，随着模型参数量和数据规模的提升，语言模型的能力及在下游任务的表现也随之提升，出现大规模的语言模型（如*175B-parameter GPT-3 and the 540B-parameter PaLM*）。在复杂任务上，大语言模型会突然出现令人惊讶的能力（*called emergent abilities*）。
  
为了系统性地介绍LLM，先总结**PLM** 与 **LLM** 的区别：
1. LLM可以在处理复杂任务中表现出惊喜的效果，但小规模的PLM做不到
2. LLM改变了开发和使用AI算法的方法，可以通过*prompting interface*来使用如*GPT-4*等大模型
3. LLM的发展不再严格区分研究和工程， LLM的训练需要在大规模数据和分布式平行训练中进行，研究者们也需要去处理非常多的工程问题

**LLM带来的影响**：
1. *Chatgpt*和*GPT-4*的出现激发了重新思考人工通用智能的可能性。OpenAI文章[*Planning for AGI and beyond*](https://openai.com/blog/planning-for-agi-and-beyond)
2. 可能作为通用语言任务求解器，新的研究范式逐渐转向如何利用LLM
3. 在信息检索领域，正在受到来自ChatGPT这种新型的信息搜索方式的挑战。
4. CV领域，研究*ChatGPT-like vision-language models*和多模态对话。
5. 应用程序领域，促使了ChatGPT和各种插件的结合

**LLM的遗留问题**：原理待探索
1. 大模型突然涌现的惊喜能力（*emergent abilities*）待解释， 更普遍的，缺乏对大模型优越能力的深入、详细的研究。
2. 研究者难以训练好的LLM， 对计算资源的巨大需求太过于昂贵。因此，LLM通常由工业界研发，具体细节难以公开。
3. 难以对齐大模型和人类的价值观，大模型有可能产生有毒、虚构或者有害的内容。

## **Overview**
### **Background for LLMs**
1. *Scaling Laws*
    - $KM$ 缩放规律： 模型性能的幂律关系模型，模型性能与*model size (N), dataset size (D), and the amount of training compute (C)*三个因素有很强的依赖关系
    - *Chinchilla scaling law*：看不懂
2. *Emergent Abilities of LLMs*
    - 定义为“*the abilities that are not present in small models but arise in large models*”
    - *In-context learning*
        - 输入中给出几个例子，大模型可以从例子中学习给出答案
    - *Instruction following*
        - 大模型可以执行新的未见过的指令
    -  *Step-by-step reasoning*
        - chain_of_thought等多步骤推理得到最终答案
3. *Key Techniques for LLMs.*
    - *Scaling*.
    - *Training*.
    - *Ability eliciting*
    - *Alignment tuning*.
    - *Tools manipulation*.

### **Technical Evolution of GPT-series Models**

<div align=center>
<img src=https://github.com/jiayuchennlp/reading_papers/blob/main/%E5%A4%A7%E6%A8%A1%E5%9E%8B/pictures/image1.png/>
</div>

GPT系列模型分为：
1. GPT-1:  *decoder-only Transformer architecture*, *unsupervised pretraining and supervised fine-tuning*
2. GPT-2： 将每一个NLP任务都转换为文本生成任务
3. GPT-3： 175B，使得*in-context learning*的能力大幅提升
4. CodeX： 在github code上训练得到的GPT模型
6. Human alignment: InstructGPT模型中运用 RHLF算法训练，减轻语言模型产生的有害的、错误的信息。随后出现了ChatGPT和GPT-4模型

这些模型的缺陷：在某些特定场景下，产生带有事实错误或者潜在危险反应的幻觉（*hallucinations*）

## **RESOURCES OF LLMS**

### 现有的大模型和接口

<div align=center>
<img src=https://github.com/jiayuchennlp/reading_papers/blob/main/%E5%A4%A7%E6%A8%A1%E5%9E%8B/pictures/image2.png/>
</div>

**LLaMA家族**
1. LLaMA, from Meta AI， 是后续各种微调变种模型的基础
2. Alpaca: based on LLaMA-7B, and 52K instruction-following data
3. Vicuna: 基于从ShareGPT收集的用户共享对话， 是多模态模型中受欢迎的选择
4. 多模态： LLaVA, MiniGPT-4, INstructBLIP, PandaGPT

**公开数据集**
<div align=center>
<img src=https://github.com/jiayuchennlp/reading_papers/blob/main/%E5%A4%A7%E6%A8%A1%E5%9E%8B/pictures/image3.png/>
</div>








   
