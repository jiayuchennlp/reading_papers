# A Survey on Multimodal Large Language Models
#### 多模态大模型持续发展的原因：
- 与人类感知世界的方式更为贴近
- 接口友好
- 能解决更多任务

本文将多模态模型分为四个类型
#### 1.Multimodal Instruction Tuning(M-IT)


- 数据如何收集
    - **Benchmark Adaptation**
        - 通常描述较为简单
            - 解决方法一： 修改instruct。把简单的短句或短语改写成句子或文章
            - 解决方法二： 扩展答案的长度，通过chatgpt
        - 与真实应用场景差距较大=》self-instruction
    - **Self-Instruction**
        - 少量人工标注的例子
        - 驱动LMs产生更多的数据
        - LLaVA扩展self-instruction到多模态领域
            - LLaVA-Instruct-150k DATASET
            - MiniGPT-4, ChatBridge, GPT4Tools, DetGPT
    - **Hybrid Composition**
        - 上述两种方式混合
- 模态之间的bridge如何搭建
    - 语言大模型只有文本的建模能力，强行加入图像信息进行end-to-end可能引发灾难性遗忘
    - 解决方法之一：加入visual encoder，在文本和图像之间搭建一个桥梁（interface）
    - **Learnable Interface**
        - frozen LLM
        - LLavA: 简单的线性层, peft版：LLaMA-Adapter
        - MedVInTTE: two-layer multilayer perceptron
        - LaVIN： mixtrue-of-modality adapter
    - **Expert Model**
        - convert multimodal inpurs into languages without training
        - 例如VideoChat-Text:
        - 不够灵活，容易导致信息遗漏
- 如何评估MMLM
    - Closed-set
        - zero-shot & finetune
    - Open-set
        - 标准：manual scoring, GPT scoring, and case study
