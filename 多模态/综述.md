# A Survey on Multimodal Large Language Models
#### 多模态大模型持续发展的原因：
- 与人类感知世界的方式更为贴近
- 接口友好
- 能解决更多任务

------


本文将多模态模型分为四个类型
<details><summary>1.Multimodal Instruction Tuning(M-IT)</summary>

![这是图片](https://github.com/jiayuchennlp/reading_papers/blob/main/%E5%A4%9A%E6%A8%A1%E6%80%81/pictures/1.png "Instruct tuning")


- 数据如何收集
    - **Benchmark Adaptation**
        - 通常描述较为简单
            - 解决方法一： 修改instruct。把简单的短句或短语改写成句子或文章
            - 解决方法二： 通过chatgpt扩展答案的长度，
        - 与真实应用场景差距较大， 改进方法：self-instruction
    - **Self-Instruction**
        - 少量人工标注的例子
        - 驱动LLMs产生更多的数据
        - LLaVA扩展self-instruction到多模态领域
            - LLaVA-Instruct-150k DATASET
            - MiniGPT-4, ChatBridge, GPT4Tools, DetGPT
    - **Hybrid Composition**
        - 上述两种方式混合
- 模态之间的bridge如何搭建
    - 语言大模型只有文本的建模能力，强行加入图像信息进行end-to-end可能引发灾难性遗忘
    - 解决方法之一：加入visual encoder，在文本和图像之间搭建一个桥梁（interface）
    - **Learnable Interface**
        - frozen LLM
        - LLavA: 简单的线性层, peft版：LLaMA-Adapter
        - MedVInTTE: two-layer multilayer perceptron
        - LaVIN： mixtrue-of-modality adapter
    - **Expert Model**
        - convert multimodal inpurs into languages without training
        - 例如VideoChat-Text:
        - 不够灵活，容易导致信息遗漏
- 如何评估MMLM
    - Closed-set
        - zero-shot & finetune
    - Open-set
        - 标准：manual scoring, GPT scoring, and case study

</details>

<details><summary>2.Multimodal In-Context Learing(M-ICL)</summary>


主要用途

1. solving various visual reasoning tasks
2. teaching LLMs to use external tools
</details>

<details><summary> 3. Multimodal Chain of Thought(M-CoT)</summary>


1. 模态壁垒
    1. **Learnable Interface**
        1. CoT-PT
        2. Multimodal-CoT
    2. **Expert Model**
2. 学习范式（learning paradigms)
    1. finetune
    2. training-free few-shot
    3. training-free zero-shot
    
    待阅读： CoT-PT, Multimodal-CoT
    
3. chain configuration
    1. adaptive and pre-defined
4. Generative Patterns
    1. infulling-based pattern????
    2. predicting-based pattern??????
</details>

<details><summary>  4. LLM-Aided Visual Reasoning(LAVR)</summary>


1. 启发： tool-augemented LLMs
2. 优点：
    1. Strong generalization abilities.
    2. Emergent abilities.
    3. Better interactivity and control.
3. training paradigms
    1. training-free
    2. fine-tune
4. LLMs的作用
    1. as Controller
    2. as Decision Maker
    3. as Semantics Refiner
</details>
