[Scaling Down to Scale Up: A Guide to Parameter-Efficient Fine-Tuning](https://arxiv.org/abs/2303.15647)

1. 动机： 模型参数量在2019年的330M暴涨到2022年的175B，增加了将近500倍，微调大模型需要大量的资源。尽管大模型有一定的zero-shot能力，但应用在下游任务上表现仍不佳。“获取更多数据”仍是在具体任务上提高性能的最佳方法。
2. 现有技术的挑战：
  - 缺乏理论理解
  - PEFT与finetune之间的gap
3. 分类：
  - 分类依据： 是否引入新的参数，是否微调大模型的部分参数
<div align=center>
<img src=https://github.com/jiayuchennlp/reading_papers/blob/main/PEFT/pictures/survey1.png/>
</div>
  - 三大类
      - Addition-based
        - Adapter-like
        - Soft prompts
      - Selection-based
      - Reparametrization-based


## Adapter Tuning

## Prefix Tuning

## Prompt Tuning

## P-tuning

## LoRA
[link](https://github.com/jiayuchennlp/reading_papers/blob/main/PEFT/LoRA.md)
